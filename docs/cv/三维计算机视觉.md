##### 三维计算机视觉

###### 立体视觉

- 立体视觉是一种计算机视觉技术，其目的是从两幅或两幅以上的图像中推理出图像中每个像素点的深度信息

- 应用领域

  - 辅助驾驶/无人驾驶
  - 机器人
  - 无人机

- 单目系统

  - 通过一个摄像头来观测目标，计算目标与摄像头的距离
  - 缺点：
    - 如果有两个物体并排，摄相机是不能确定到目标距离相机的位置的

- 双目系统

  - 简单说就是左右两个方向都设一个摄像头，类似于人类的两只眼睛，这样就能确定到物体与相机的距离与位置了

  - ![双目系统](image-20200830154428327.png)

  - 要记住几个概念

    - 极平面：O 1 , O 2 , P三个点确定的平面
    - 极点：O 1 O 2 连线与像平面I 1 、I 2 的交点e 1 、e 2
    - 基线：O 1 , O 2
    - 极线：极平面与两个像平面之间的交线l 1 、l 2

  - 双目系统如何计算目标点与基线的距离

    - ![双目系统获取目标点到基线的距离](image-20200830154756590.png)

    - 原理就是根据三角相似定理

      - $$
        \frac{B}{Z} = \frac{pp'}{Z-f}=\frac{B- (XR - \frac{W}{2}) - (\frac{W}{2} - XT)}{Z-f} = \frac{B + XT -XR}{Z - f}
        $$

      - $$
        Z =\frac{B * f}{XR - XT} = \frac{B * f}{D}
        $$

      - Z在这里就指的是深度图像

- 视差

  - 将同一空间物理点在不同图像中的映像点对应起来，这个差别，我们称做视差图像(通俗来讲，一个物体在左眼和右眼成像)

  - D 为视差

  - $$
    Z = \frac{B·f}{xR - xT} = \frac{B·f}{D}
    $$

  - 视差与深度的关系(反比)

    - ![视差与深度关系图](image-20200830162134320.png)

- 要求算力要非常快

###### SIFT(尺度不变特征变换)

- sift提取图像的局部特征，在尺度空间寻找极值点，并提取出其位置、尺度、方向信息

- sift特征的特点
  - 对旋转、尺度缩放、亮度变化保持不变性，对视角变化、噪声等也存在一定程度的稳定性
  - 独特性，信息量丰富，适用于在海量特征数据中进行快速，准确的匹配
  - 多量性，即使少数几个物体也可以产生大量的sift特征向量
  - 可扩展性，可以很方便的与其他形式的特征向量进行联合
  
- sift的实质
  - 在不同的尺度空间上查找关键点(特征点)，计算关键点的大小、方向、尺度信息，利用这些信息组成关键点对特征点进行描述的问题。
  - sift所查找的关键点都是一些十分突出，不会因光照，仿射变换和噪声等因素而变换的"稳定"特征点，如角点、边缘点、暗区的亮点以及亮区的暗点等
  
- 具体步骤
  - **生成高斯差分金字塔(DOG金字塔)，尺度空间构造**
    - 尺度空间：试图在图像领域中模拟人眼观察物体的概念与方法(通俗说，尺度空间，就相当于一个图片需要获得多少分辨率的量级)
      
      - 例如：观察一棵树，关键在于我们想要观察是树叶还是整棵树；如果是一整棵树(相当于大尺度情况下观察)，那么就应该去除图像的细节部分。如果是树叶(小尺度情况下观察)，那么就该观察局部细节特征
    - 图像金字塔：如果把一个图片从原始分辨率不停的对其分辨率进行减少，然后将这些图片摞在一起，可以看成一个四棱锥的样式(由不同分辨率的图像组成的一个金字塔)
      - 获得图像金字塔步骤
        - 利用低通滤波器平滑图像(高斯滤波)
        - 对平滑图像进行抽样(采样)
          - 上下采样
    - **高斯金字塔**
      
      - 高斯金字塔不是一个金字塔，而是有很多组金字塔构成，并且每组金字塔都包含若干层
      
      - **构建过程**
        - 先将原图扩大一倍之后作为高斯金字塔的第一组第一层，将第一组第一层图像经高斯卷积之后作为第一组金字塔的第二层
        
        - 将σ乘以一个比例系数k,得到一个新的平滑因子σ=k*σ，用它来平滑第1组第2层图像，结果图像作为第3层
        
          - **高斯金字塔的k值**
        
            - $$
              k = 2^\frac{1}{S}
              $$
        
              
        
            - S：每组图像中检测s个尺度的极值点(实际计算时，S通常在3到5之间)
        
            - Sift算法中生成高斯金字塔的规则(M,N为原始图像的行数和列数)：
        
              - 设高斯金字塔共包含O组图像，每组图像有S+3层
        
              - $$
                O = log_2{(min\{M,N\})} - 3
                $$
        
                
        
        - 如此这般重复，最后得到L层图像，在同一组中，每一层图像的尺寸都是一样的，只是平滑系数不一样。它们对应的平滑系数分别为：0，σ，kσ，k^2σ,k^3σ……k^(L-2)σ
        
        - 将第1组倒数第三层图像作比例因子为2的降采样，得到的图像作为第2组的第1层，然后对第2组的第1层图像做平滑因子为σ的高斯平滑，得到第2组的第2层，就像步骤2中一样，如此得到第2组的L层图像，同组内它们的尺寸是一样的，对应的平滑系数分别为：0，σ，kσ，k^2σ,k^3σ……k^(L-2)σ。
          但是在尺寸方面第2组是第1组图像的一半
          
        - 反复执行，就可以得到一共O组，每组L层，共计O*L个图像，这些图像一起就构成了高斯金字塔
        
      - 特点：
        - 在同一组内，不同层图像的尺寸是一样的，后一层图像的高斯平滑因子σ是前一层图像平滑因子的k倍
        - 在不同组内，后一组第一个图像是前一组倒数第三个图像的二分之一采样，图像大小是前一组的一半
        
      - 高斯差分金字塔的目的
        - 减到有共性的地方减掉，留下的点为特征点
        - 归一化：将像素变的更集中(在sift过程中不需要)
        
      - 利用高斯核函数进行滤波的主要原因：
        - 高斯核函数是唯一的尺度不变核函数
        - DoG核函数可以近似为LoG函数，这样可以使特征提取更加简单
        
      - 其实尺度空间图像生成就是当前图像与不同尺度核参数σ进行卷积运算后产生的图像
    - DoG金字塔(差分金字塔)
      - 尺度空间构建的基础是DOG金字塔，DOG金字塔构建的基础是高斯金字塔
      - DOG（Difference of Gaussian）金字塔是在高斯金字塔的基础上构建起来的，
        其实生成高斯金字塔的**目的**就是为了构建DOG金字塔
        - DOG金字塔的**第1组第1层**是由高斯金字塔的**第1组第2层减第1组第1层**得到的
    
  - 尺度空间极值点检测
    
    - 特征点是由DOG空间的局部极值点组成的，为了寻找DoG函数的极值点，**每一个像素点要和它所有的相邻点比较**，看其是否比它的图像域和尺度域的相邻点大或者小，这里就是获取**极大值或极小值点**
    - sift尺度空间(**考点**)
      - 高斯模糊，在高斯金字塔多模糊出三张凑数，这样才能保证上下边邻域可以求极值，DOG中多两张(这里解释的多模糊出三张是相对于最终的尺度来说的，DOG为尺度空间+2，高斯金字塔为尺度空间+3，尺度也就是上边提到的s值)
    
  - 稳定关键点的精确定位
    - 找关键点
    - DOG值对噪声和边缘比较敏感，所以在第2步的尺度空间中检测到的局部极值点还要经过一步的筛选，祛除不稳定和错误检测出的极值点
    - **利用阈值的方法来限制，在opencv中为contrastThreshold**
    - 对精度要求很高，就要谨慎这来使用，如果对精度不高可以不是操作
    
  - 稳定关键点方向信息分配
    
    - 稳定的极值点是在不同尺度空间下提取的，这保证了关键点的尺度不变形
    
    - 为关键点分配方向信息所要解决的问题是使得关键点对图像角度和旋转具有不变性
    
    - 具体实践
    
      - 获取关键点所在尺度空间的邻域，然后计算该区域的梯度和方向，根据计算得到的结果创建方向直方图，直方图的峰值为主方向的参数，其他高于主方向百分之八十的方向被判定为辅助方向，这样设定对稳定性有很大帮助
    
    - 为什么是八个方向
    
      - 每个邻域有8个点
    
    - 幅值表述
    
      - $$
        m(x,y) = \sqrt{(L(x+1,y) - L(x-1,y))^2 + (L(x,y+1)-L(x,y-1))^2}
        $$
    
        
    
    - 梯度方向表述
    
      - $$
        θ(x,y) = tan^{-1}[\frac{L(x+1,y) - L(x-1,y)}{L(x,y+1)-L(x,y-1)}]
        $$
    
        
    
  - 关键点描述
    
    - 对于每一个关键点，都拥有位置、尺度以及方向三个信息，所以具备平移、缩放、旋转不变性
    - **描述思路**
      - 对关键点周围像素区域分块，计算块内梯度直方图，生成具有独特性的向量，这个向量是该区域图像信息的一种抽象表述
      - ![image-20200831230347651](image-20200831230347651.png)
    
  - 特征点匹配
    - 特征点的匹配是通过计算两组特征点的128维的关键点的欧式距离实现的
    - 欧式距离越小，则相似度越高，当欧式距离小于设定的阈值时，可以判定为匹配成功

- 代码实现

  - SIFT函数注册了专利，在商业用途上是收费的。将在opencv > 3.4.3中，不再提供
  - 解决办法
    - 安装opencv-python 3.4.2.16
    - 以及opencv-contrib-python 3.4.2.16
    - 使用conda和pip安装
    - pip install opencv-python ==3.4.2.16
    - pip install opencv-contrib-python==3.4.2.16

  > ```python
  > import cv2
  > import numpy as np
  > 
  > # 特征匹配
  > def drawMatchesKnn_cv2(img1_gray,kp1,img2_gray,kp2,goodMatch):
  >     h1, w1 = img1_gray.shape[:2]
  >     h2, w2 = img2_gray.shape[:2]
  >  
  >     vis = np.zeros((max(h1, h2), w1 + w2, 3), np.uint8)
  >     vis[:h1, :w1] = img1_gray
  >     vis[:h2, w1:w1 + w2] = img2_gray
  >  
  >     p1 = [kpp.queryIdx for kpp in goodMatch]
  >     p2 = [kpp.trainIdx for kpp in goodMatch]
  >  
  >     post1 = np.int32([kp1[pp].pt for pp in p1])
  >     post2 = np.int32([kp2[pp].pt for pp in p2]) + (w1, 0)
  >  
  >     for (x1, y1), (x2, y2) in zip(post1, post2):
  >         cv2.line(vis, (x1, y1), (x2, y2), (0,0,255))
  >  
  >     cv2.namedWindow("match",cv2.WINDOW_NORMAL)
  >     cv2.imshow("match", vis)
  > 
  > # 读取图片
  > img1_gray = cv2.imread("iphone1.png")
  > img2_gray = cv2.imread("iphone2.png")
  >  
  > #sift = cv2.SIFT()
  > # 初始化sift
  > sift = cv2.xfeatures2d.SIFT_create()
  > #sift = cv2.SURF()
  >  
  > # 获取特征点和描述 
  > kp1, des1 = sift.detectAndCompute(img1_gray, None)
  > kp2, des2 = sift.detectAndCompute(img2_gray, None)
  >  
  > # BFmatcher with default parms
  > bf = cv2.BFMatcher(cv2.NORM_L2)
  > matches = bf.knnMatch(des1, des2, k = 2)
  > 
  > goodMatch = []
  > for m,n in matches:
  >     if m.distance < 0.50*n.distance:
  >         goodMatch.append(m)
  >  
  > drawMatchesKnn_cv2(img1_gray,kp1,img2_gray,kp2,goodMatch[:20])
  >  
  > cv2.waitKey(0)
  > cv2.destroyAllWindows()
  > ```
  >
  > 

​	

​	

